# Winter-Semester-2025-26---MACSE605---Large-Language-Models-Project

Abstract:
Legal research is a fundamental yet time-consuming task in the judicial and legal domains, as it requires analyzing large volumes of judicial judgments and identifying relevant precedents. Traditional legal information retrieval systems mainly rely on keyword-based search techniques, which fail to capture the complex relationships between cases and often lack reasoning and explainability. With the increasing availability of digital legal documents, there is a growing need for intelligent systems that can perform structured, accurate, and explainable legal reasoning.

This project proposes an AI-based legal case reasoning system using Transformer models and Graph-based Retrieval Augmented Generation (GraphRAG). Judicial judgments are processed using Transformer-based natural language processing techniques to extract legal entities, citations, and key concepts. These extracted elements are then organized into a legal knowledge graph, representing precedent relationships among cases. GraphRAG is employed to retrieve relevant subgraphs based on user queries, enabling multi-hop reasoning over judicial precedents. Finally, a Transformer-based language model generates clear and explainable legal responses supported by citation paths.

The proposed system improves the accuracy, transparency, and efficiency of legal research by reducing hallucinations, enabling precedent-aware reasoning, and providing explainable outputs. This approach demonstrates the potential of combining Transformers with structured knowledge graphs for reliable and intelligent legal decision-support systems.

<img width="1007" height="542" alt="image" src="https://github.com/user-attachments/assets/3c1feb34-3413-4c65-b171-6548fad9b31b" />
<img width="982" height="386" alt="image" src="https://github.com/user-attachments/assets/062861ea-450e-49ff-b219-c762dd1fe887" />

